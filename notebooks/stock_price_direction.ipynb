{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed272f1-6452-4360-9a7a-f8c3ee60b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05104d02-e94d-43b0-b3b8-3d61a4ec9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training set\n",
    "df_train = pd.read_csv(\"/Users/Golnoush/Desktop/Stock_price_direction/data/raw/AMZN_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4759a-5dfe-412a-9ef9-509aa6f8ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938cd64-8cb3-4fcb-9831-30e0c6d6ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f303eaf-f6ff-4b1b-87ed-187073e35de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8d596-ac9d-4a07-b2f4-dceb234a4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Date\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6061b8e-7890-4a44-968b-c7a4a828dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the time range\n",
    "df_train[\"Date\"].min(), df_train[\"Date\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53eacf9-59dd-4a6b-a711-175c8b9fdd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 9)\n",
    "_ = df_train.plot(x=\"Date\", y=[\"Close\", \"Open\", \"High\", \"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182b726-79a6-49f7-b7a8-8cd4fa5b55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(dataframe):\n",
    "    \"\"\"Runs an exploration analysis of the dataframe.\"\"\"\n",
    "    print(\"Shape\", dataframe.shape, \"\\n\")\n",
    "    print(\"Columns\", dataframe.columns, \"\\n\")\n",
    "    dataframe.info()\n",
    "    print(\"\\n\", dataframe.describe(), \"\\n\")\n",
    "    print(\"The data ranges from\", dataframe[\"Date\"].min(), \"to\", dataframe[\"Date\"].max())\n",
    "    dataframe.plot(x=\"Date\", y=[\"Close\", \"Open\", \"High\", \"Low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a71ec3-572d-4025-b850-bcee2e07eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read validation and test sets and then analyse them\n",
    "df_val = pd.read_csv(\"/Users/Golnoush/Desktop/Stock_price_direction/data/raw/AMZN_val.csv\")\n",
    "analyse(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c94683-9741-4774-a564-8194a320a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/Users/Golnoush/Desktop/Stock_price_direction/data/raw/AMZN_test.csv\")\n",
    "analyse(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9086b1-f31f-40d5-a76e-a0c6771138ad",
   "metadata": {},
   "source": [
    "Once we have done our exploration of the data, we can move on to the predictive modeling part of the task. The task was to predict if the next day's closing price will be higher than the opening price. We do not have that information explicitly in our data, so we have to infer it.\n",
    "\n",
    "This is relatively simple, we just need to compare the closing and opening prices one day in advance.\n",
    "\n",
    "To achieve that, first, we will make sure that the data is sorted by the date. We can use the sort_values method and pass in the Date column as a parameter, sorting it in ascending order.\n",
    "\n",
    "Next, we need to shift the DataFrame by one row / one day and compare the prices. Pandas has a method for doing exactly that, the shift method. We specify a period of minus one (so that we shift the data from the next day back). Because it is a logical operation, Pandas would return a True / False result for each comparison. We want this to be presented as 1 / 0 for the machine learning models, so we will map it to type int. To store all of this information, we will create a new column, called Target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff7988-1b61-4211-8102-1753aeaa89ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that our data is sorted by date\n",
    "df_train.sort_values(by=\"Date\", inplace=True)\n",
    "df_val.sort_values(by=\"Date\", inplace=True)\n",
    "df_test.sort_values(by=\"Date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e735fa-7e7d-4e93-8046-ddd06c0c5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that we shift by a period of '-1', this takes the next day's price direction for the current day\n",
    "# a positive period will take the days from the past\n",
    "df_train[\"Target\"] = (df_train[\"Close\"] > df_train[\"Open\"]).shift(periods=-1, fill_value=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b6ebf-5f5d-4d3c-b143-91cf1fbdbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fccded-df5b-4076-933e-fe453af49898",
   "metadata": {},
   "source": [
    "Running the value_counts method on the Target column gives us the distribution. We have 2292 days where the closing price is higher than the opening and 2389 where it is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d1abe-87f3-43cb-bbf2-8bc74e13bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e47eb7-c744-4a33-a642-8b8143fe6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"Target\"] = (df_val[\"Close\"] > df_val[\"Open\"]).shift(periods=-1, fill_value=0).astype(int)\n",
    "df_val[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfab670-9873-4f8f-aebc-f352030a0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Target\"] = (df_test[\"Close\"] > df_test[\"Open\"]).shift(periods=-1, fill_value=0).astype(int)\n",
    "df_test[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3bf4b-d384-4121-b70e-2f93e1482a94",
   "metadata": {},
   "source": [
    "At this point, we can start building some machine learning models to predict the target variable. But, before we do that, it might be useful to engineer some additional features that may help us better predict the price direction. In the next section, we will explore some possibilities for doing feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca53956-1aa9-411b-963a-c2e6b613ac33",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "\n",
    "We know that the stock prices are time-dependent and that the next day's price depends on prices (and many other things) from previous days.\n",
    "\n",
    "We want to somehow take into account all the values in the last n days, capturing the trend, or the magnitude of price change.\n",
    "\n",
    "A simple solution would be to calculate a moving average. With Pandas, we can use the rolling method to calculate moving averages. It provides us with an interface for sliding (in Pandas terminology - rolling) window calculations. The following cells calculate the 3- and 7-days moving average, and add them as a feature into the data set.\n",
    "\n",
    "Remember that we have our data sorted from before. If the data is not sorted by the date, the results from the rolling() method would be invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d152325-afd9-4495-960e-048897936d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Moving_Average_3\"] = (df_train[\"Close\"] - df_train[\"Open\"]).rolling(window=3, min_periods=1).mean()\n",
    "df_val[\"Moving_Average_3\"] = (df_val[\"Close\"] - df_val[\"Open\"]).rolling(window=3, min_periods=1).mean()\n",
    "df_test[\"Moving_Average_3\"] = (df_test[\"Close\"] - df_test[\"Open\"]).rolling(window=3, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f27b1c-54b0-479c-bdb6-f0d3ccc296e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Moving_Average_7\"] = (df_train[\"Close\"] - df_train[\"Open\"]).rolling(window=7, min_periods=1).mean()\n",
    "df_val[\"Moving_Average_7\"] = (df_val[\"Close\"] - df_val[\"Open\"]).rolling(window=7, min_periods=1).mean()\n",
    "df_test[\"Moving_Average_7\"] = (df_test[\"Close\"] - df_test[\"Open\"]).rolling(window=7, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a1d52-c951-4873-aba6-99b324ecd0f4",
   "metadata": {},
   "source": [
    "Feature engineering can be simpler, we can just take the current day's price direction or the price range. Anything that comes to mind, that can be considered to be useful, should be tested and tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527650f-709f-48c5-a7e9-4d56f0998660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current price direction\n",
    "df_train[\"Today_Direction\"] = df_train[\"Close\"] - df_train[\"Open\"]\n",
    "df_val[\"Today_Direction\"] = df_val[\"Close\"] - df_val[\"Open\"]\n",
    "df_test[\"Today_Direction\"] = df_test[\"Close\"] - df_test[\"Open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c07766-dee2-43f1-b217-072cf50f0fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price range\n",
    "df_train[\"Price_Range\"] = df_train[\"High\"] - df_train[\"Low\"]\n",
    "df_val[\"Price_Range\"] = df_val[\"High\"] - df_val[\"Low\"]\n",
    "df_test[\"Price_Range\"] = df_test[\"High\"] - df_test[\"Low\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59b299-8882-4891-8431-4a02a410d69a",
   "metadata": {},
   "source": [
    "The next cell displays a sample of the data with the new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af5e4d-26c0-46da-9843-be6e126c9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd320771-23a7-42d2-953c-9c91f11866d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the target column that we aim to predict\n",
    "y_col = \"Target\"\n",
    "# these are the input features for the models\n",
    "X_cols = [\n",
    "    \"Open\",\n",
    "    \"Close\",\n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Volume\",\n",
    "    \"Adj Close\",\n",
    "    \"Today_Direction\",\n",
    "    \"Moving_Average_3\",\n",
    "    \"Moving_Average_7\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a68e43-9450-46f4-8f8d-d1518543d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[X_cols]\n",
    "y_train = df_train[y_col]\n",
    "\n",
    "X_val = df_val[X_cols]\n",
    "y_val = df_val[y_col]\n",
    "\n",
    "X_test = df_val[X_cols]\n",
    "y_test = df_val[y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb402a6-bba2-4551-af79-22e95ec7fd80",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "\n",
    "We start our modeling phase with a LogisticRegression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03064e1-eef7-4a0c-b456-3e71724f7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# use default parameters\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# fit to train set\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# plot ROC curve, and show AUC for the validation set\n",
    "RocCurveDisplay.from_estimator(lr, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0473731c-4a87-4a83-b32d-8be4ad6d0175",
   "metadata": {},
   "source": [
    "Logistic regression does not work well for this problem. Having AUC < 0.5 means that the classifier is worse than just randomly guessing the output. Given that we are dealing with a very difficult problem, any AUC > 0.5 would suffice for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df31a9-9669-48c2-8f07-4666b36c143a",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389ad6a6-16b7-4f4e-ac7c-6e49d4323e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "RocCurveDisplay.from_estimator(dt, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8de5ac-2b3b-47f5-9464-ef3dea196e5d",
   "metadata": {},
   "source": [
    "The decision tree outperforms the logistic regression model by 0.02, and its AUC is above 0.5!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de74e6-5c9d-482f-8e2f-26e7753f36b8",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878af463-0f74-4fd6-b078-a9fe80ad465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "RocCurveDisplay.from_estimator(rf, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cdeee5-2e01-44a8-ba9b-715dad2d8034",
   "metadata": {},
   "source": [
    "Contrary to our expectation, the model does not outperform the decision tree, it actually performs the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c0fcd-8839-4103-b3d8-aa57e2649aff",
   "metadata": {},
   "source": [
    "Gradient Boosting Ensemble\n",
    "\n",
    "One last ensemble technique that we would like to try is gradient boosting. This algorithm sets up the stage for our next part, where we will try a deep learning approach to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0a468-f355-4ac9-8732-f7e0ce5ac805",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=RANDOM_SEED)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "RocCurveDisplay.from_estimator(gb, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29abb6-5dad-463b-9154-87fe488a0c50",
   "metadata": {},
   "source": [
    "the gradient boosting classifier outperform previous models and scored 0.55 AUC!\n",
    "\n",
    "We find out that gradient boosting works best for this data set. In the next section, we will train a deep learning model with the aim to outperform the baseline set here, i.e., AUC = 0.55."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275c9a7-9054-4d9d-87f1-6b11407aa3c2",
   "metadata": {},
   "source": [
    "Deep Learning\n",
    "Using Tensorflow to implement a small neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8f687-0633-40aa-8c7a-f703fc32ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility of results\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Tensorflow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b8f70-84ec-4eeb-967f-464744dd1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Normalization(axis=-1),\n",
    "    tf.keras.layers.Dense(10, input_shape=[X_train.shape[1],], activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'),\n",
    "    tf.keras.layers.Dropout(0.2, seed=RANDOM_SEED),\n",
    "    tf.keras.layers.Dense(5, activation=\"relu\", kernel_initializer='random_normal', bias_initializer='zeros'),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\", kernel_initializer='random_normal', bias_initializer='zeros')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033978b-3bd8-4f31-bc0c-1de78b9a975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this configures the model's loss function, weight optimizer, and metrics to keep track of\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    metrics=['AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbca4a-f3c6-41e0-8373-fe205180ffea",
   "metadata": {},
   "source": [
    "We are going to train our model for 50 epochs, and keep track of its loss (binary_crossentropy) and AUC values during each epoch.\n",
    "\n",
    "To prevent overfitting, we are implementing two callbacks: (1) learning rate scheduler, and (2) early stopping callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea9b7d-182f-4b78-9d4f-8dd1730f7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_scheduler(epoch, learning_rate):\n",
    "    \"\"\"Learning rate decay callback.\"\"\"\n",
    "    if epoch < 5:\n",
    "        return learning_rate\n",
    "    else:\n",
    "        return learning_rate * tf.math.exp(-0.01)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n",
    "learning_rate_callback = tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed22bcd-d485-4efe-a26e-70efa04b89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model.fit(...) method returns a 'history' object with stats about the training\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping_callback, learning_rate_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743c5d4-7647-43ca-85ea-321cd3743447",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130d9e8-8eb8-4147-bb32-da3525860c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [Price]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc168c85-3fbe-4e6d-a475-64ae5933beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['auc'], label='auc')\n",
    "plt.plot(history.history['val_auc'], label='val_auc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [Price]')\n",
    "plt.legend()\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d57be2-5d56-47b1-a94b-9027192295ad",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "The gradient boosting classifier provided the best AUC score on the validation set.\n",
    "It is a common machine learning practice to train multiple models on the same train/validation data set and provide a model that works best.\n",
    "To simulate a production environment, we have held the test set aside until now.\n",
    "\n",
    "In the next cell, we are going to evaluate the performance of the gradient boosting classifier on the test set. \n",
    "This is simple as calling plot_roc_curve with the test set instead of the validation one.\n",
    "\n",
    "In the last cell, I will look at the feature importance plot, which plots the importance of each feature in regard to the predictive performance of the model (the higher the value the more important the feature is for determining the value of the target variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db635e6-a3e8-489b-b39e-1ebbfe9b43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(gb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc241a59-d958-4b2e-b403-cd6214f0478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating feature importances\n",
    "importances = gb.feature_importances_\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [df_train[X_cols].columns[i] for i in indices]\n",
    "\n",
    "_ = plt.figure(figsize=(9, 7))\n",
    "plt.bar(names, importances[indices])\n",
    "_ = plt.title(\"Feature importance\")\n",
    "_ = plt.xticks(rotation=20, fontsize = 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
